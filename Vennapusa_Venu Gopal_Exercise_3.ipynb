{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Venu-GR/INFO-5731_Venu-GR/blob/main/Vennapusa_Venu%20Gopal_Exercise_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 3**\n",
        "\n",
        "The purpose of this exercise is to explore various aspects of text analysis, including feature extraction, feature selection, and text similarity ranking.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of Friday, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting **text classification or text mining task** and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features. **Your dataset must be text.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task: Sentiment Analysis on movie reviews.\n",
        "\n",
        "Features:\n",
        "Bag-of-Words: This counts the occurrence frequency of each word in the text. This feature helps in the extraction of common words which may indicate sentiment, such as \"great,\" \"bad,\" and \"terrible.\"\n",
        "TF-IDF: It measures the importance of a word in a document with respect to the entire corpus. It filters out the common words such as \"the\" that do not contribute much to the information in sentiment analysis.\n",
        "POS Tags: Nouns, verbs, adjectives, etc. Adjectives such as \"awesome\" or \"horrible\" quite often give a good indication of text sentiment.\n",
        "Sentiment Score: This provided the overall sentiment of each review-whether it was positive or negative. This score has helped in direct classification.\n",
        "N-grams (Bigrams or Trigrams): They seize the contexts better in sequences of two and three words than the single word, such as \"not good\" versus \"good.\"."
      ],
      "metadata": {
        "id": "138s5GQEPK5Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3537751f-3251-40fe-93b9-4919c0118270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.25285877 0.         0.         ... 0.03614657 0.         0.04080097]\n",
            " [0.         0.         0.         ... 0.05910942 0.         0.05004047]\n",
            " [0.         0.06239651 0.         ... 0.02973227 0.03119825 0.        ]\n",
            " [0.         0.         0.         ... 0.03682596 0.         0.        ]\n",
            " [0.         0.         0.02281182 ... 0.02173991 0.         0.        ]]\n",
            "\n",
            "POS Tags for sentence (first 100 chars):  plot : two teen couples go to a church party , drink and then drive . \n",
            "they get into an accident . \n",
            " ...\n",
            "[('plot', 'NN'), (':', ':'), ('two', 'CD'), ('teen', 'NN'), ('couples', 'NNS'), ('go', 'VBP'), ('to', 'TO'), ('a', 'DT'), ('church', 'NN'), ('party', 'NN'), (',', ','), ('drink', 'NN'), ('and', 'CC'), ('then', 'RB'), ('drive', 'NN'), ('.', '.'), ('they', 'PRP'), ('get', 'VBP'), ('into', 'IN'), ('an', 'DT')]\n",
            "\n",
            "POS Tags for sentence (first 100 chars):  the happy bastard's quick movie review \n",
            "damn that y2k bug . \n",
            "it's got a head start in this movie sta ...\n",
            "[('the', 'DT'), ('happy', 'JJ'), ('bastard', 'NN'), (\"'s\", 'POS'), ('quick', 'JJ'), ('movie', 'NN'), ('review', 'NN'), ('damn', 'NN'), ('that', 'WDT'), ('y2k', 'VBZ'), ('bug', 'NN'), ('.', '.'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('got', 'VBD'), ('a', 'DT'), ('head', 'JJ'), ('start', 'NN'), ('in', 'IN'), ('this', 'DT')]\n",
            "\n",
            "POS Tags for sentence (first 100 chars):  it is movies like these that make a jaded movie viewer thankful for the invention of the timex indig ...\n",
            "[('it', 'PRP'), ('is', 'VBZ'), ('movies', 'NNS'), ('like', 'IN'), ('these', 'DT'), ('that', 'WDT'), ('make', 'VBP'), ('a', 'DT'), ('jaded', 'JJ'), ('movie', 'NN'), ('viewer', 'NN'), ('thankful', 'NN'), ('for', 'IN'), ('the', 'DT'), ('invention', 'NN'), ('of', 'IN'), ('the', 'DT'), ('timex', 'JJ'), ('indiglo', 'NN'), ('watch', 'NN')]\n",
            "\n",
            "POS Tags for sentence (first 100 chars):   \" quest for camelot \" is warner bros . ' first feature-length , fully-animated attempt to steal clo ...\n",
            "[('``', '``'), ('quest', 'JJS'), ('for', 'IN'), ('camelot', 'NN'), ('``', '``'), ('is', 'VBZ'), ('warner', 'JJ'), ('bros', 'NNS'), ('.', '.'), (\"'\", \"''\"), ('first', 'JJ'), ('feature-length', 'JJ'), (',', ','), ('fully-animated', 'JJ'), ('attempt', 'NN'), ('to', 'TO'), ('steal', 'VB'), ('clout', 'NN'), ('from', 'IN'), ('disney', 'NN')]\n",
            "\n",
            "POS Tags for sentence (first 100 chars):  synopsis : a mentally unstable man undergoing psychotherapy saves a boy from a potentially fatal acc ...\n",
            "[('synopsis', 'NN'), (':', ':'), ('a', 'DT'), ('mentally', 'RB'), ('unstable', 'JJ'), ('man', 'NN'), ('undergoing', 'VBG'), ('psychotherapy', 'JJ'), ('saves', 'NNS'), ('a', 'DT'), ('boy', 'NN'), ('from', 'IN'), ('a', 'DT'), ('potentially', 'RB'), ('fatal', 'JJ'), ('accident', 'NN'), ('and', 'CC'), ('then', 'RB'), ('falls', 'VBZ'), ('in', 'IN')]\n",
            "[[2 1 1 ... 1 0 1]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from textblob import TextBlob\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "txt = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()[:5]]\n",
        "vectorizer = CountVectorizer()\n",
        "tv = TfidfVectorizer()\n",
        "features = tv.fit_transform(txt).toarray()\n",
        "print(features)\n",
        "for sentence in txt:\n",
        "  tokens = word_tokenize(sentence)\n",
        "  print(\"\\nPOS Tags for sentence (first 100 chars): \", sentence[:100], \"...\")\n",
        "  print(pos_tag(tokens[:20]))\n",
        "for sentence in txt:\n",
        "  blob = TextBlob(sentence)\n",
        "ngram = CountVectorizer(ngram_range=(2, 2))\n",
        "bigrams = ngram.fit_transform(txt).toarray()\n",
        "print(bigrams)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CRuXfV570ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f89c71-bd3c-449f-9b78-a981a15ff1b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top features ranked by importance (Chi-Square):\n",
            " [('the', 24.399176954732507), ('is', 13.36011904761905), ('it', 12.517241379310349), ('not', 10.0), ('film', 8.245098039215687), ('stalked', 8.000000000000002), ('quest', 7.5), ('10', 6.666666666666666), ('to', 6.000000000000002), ('camelot', 6.0), ('kayley', 6.0), ('that', 5.4696969696969715), ('about', 4.666666666666666), ('audience', 4.666666666666666), ('daryl', 4.666666666666666), ('make', 4.666666666666666), ('arthur', 4.499999999999998), ('baldwin', 4.499999999999998), ('disney', 4.499999999999998), ('ship', 4.499999999999998), ('he', 4.378787878787879), ('are', 4.166666666666667), ('and', 4.120098039215689), ('brooke', 4.000000000000001), ('show', 4.000000000000001), ('stalker', 4.000000000000001), ('then', 4.000000000000001), ('after', 3.333333333333333), ('been', 3.333333333333333), ('cool', 3.333333333333333), ('does', 3.333333333333333), ('all', 3.282051282051283), ('one', 3.282051282051283), ('in', 3.000000000000001), ('animation', 3.0), ('cartoon', 3.0), ('crew', 3.0), ('curtis', 3.0), ('dragon', 3.0), ('early', 3.0), ('few', 3.0), ('footage', 3.0), ('garrett', 3.0), ('gore', 3.0), ('kick', 3.0), ('least', 3.0), ('personality', 3.0), ('power', 3.0), ('robots', 3.0), ('round', 3.0), ('sutherland', 3.0), ('table', 3.0), ('why', 3.0), ('will', 3.0), ('here', 2.8809523809523805), ('an', 2.7222222222222237), ('there', 2.7222222222222237), ('because', 2.666666666666667), ('films', 2.666666666666667), ('go', 2.666666666666667), ('guess', 2.666666666666667), ('have', 2.666666666666667), ('his', 2.666666666666667), ('house', 2.666666666666667), ('or', 2.666666666666667), ('plot', 2.666666666666667), ('video', 2.666666666666667), ('of', 2.5423280423280445), ('which', 2.520833333333334), ('even', 2.011904761904762), ('actually', 2.0000000000000004), ('based', 2.0000000000000004), ('before', 2.0000000000000004), ('bit', 2.0000000000000004), ('both', 2.0000000000000004), ('boy', 2.0000000000000004), ('character', 2.0000000000000004), ('doesn', 2.0000000000000004), ('door', 2.0000000000000004), ('genre', 2.0000000000000004), ('hair', 2.0000000000000004), ('late', 2.0000000000000004), ('man', 2.0000000000000004), ('mind', 2.0000000000000004), ('minutes', 2.0000000000000004), ('movies', 2.0000000000000004), ('music', 2.0000000000000004), ('nice', 2.0000000000000004), ('number', 2.0000000000000004), ('obvious', 2.0000000000000004), ('part', 2.0000000000000004), ('psycho', 2.0000000000000004), ('simply', 2.0000000000000004), ('things', 2.0000000000000004), ('us', 2.0000000000000004), ('ve', 2.0000000000000004), ('watch', 2.0000000000000004), ('by', 1.9285714285714288), ('into', 1.9285714285714288), ('more', 1.9285714285714288), ('way', 1.9285714285714288), ('what', 1.9285714285714288), ('who', 1.9285714285714288), ('but', 1.9215686274509816), ('on', 1.855072463768117), ('this', 1.852564102564103), ('don', 1.6874999999999996), ('1997', 1.5), ('20th', 1.5), ('90s', 1.5), ('able', 1.5), ('accidentally', 1.5), ('across', 1.5), ('action', 1.5), ('adults', 1.5), ('adventures', 1.5), ('anastasia', 1.5), ('angry', 1.5), ('animated', 1.5), ('arguing', 1.5), ('arrival', 1.5), ('aside', 1.5), ('average', 1.5), ('awfully', 1.5), ('balki', 1.5), ('bastard', 1.5), ('battle', 1.5), ('beat', 1.5), ('belated', 1.5), ('below', 1.5), ('bland', 1.5), ('blind', 1.5), ('body', 1.5), ('booby', 1.5), ('brain', 1.5), ('bringing', 1.5), ('bronson', 1.5), ('bros', 1.5), ('brother', 1.5), ('bug', 1.5), ('carey', 1.5), ('case', 1.5), ('celine', 1.5), ('century', 1.5), ('cgi', 1.5), ('challenger', 1.5), ('chance', 1.5), ('children', 1.5), ('climb', 1.5), ('clout', 1.5), ('cloying', 1.5), ('colorful', 1.5), ('comedy', 1.5), ('compare', 1.5), ('computerized', 1.5), ('contest', 1.5), ('crown', 1.5), ('damn', 1.5), ('dangerous', 1.5), ('daughter', 1.5), ('deserted', 1.5), ('design', 1.5), ('differentiates', 1.5), ('dion', 1.5), ('donald', 1.5), ('dream', 1.5), ('drunkenly', 1.5), ('dull', 1.5), ('dweller', 1.5), ('element', 1.5), ('elwes', 1.5), ('empire', 1.5), ('empty', 1.5), ('enthusiastic', 1.5), ('eric', 1.5), ('error', 1.5), ('essential', 1.5), ('evil', 1.5), ('excalibur', 1.5), ('expected', 1.5), ('fall', 1.5), ('fans', 1.5), ('father', 1.5), ('feature', 1.5), ('fighter', 1.5), ('flashy', 1.5), ('flawed', 1.5), ('follow', 1.5), ('footsteps', 1.5), ('forest', 1.5), ('forgettable', 1.5), ('fox', 1.5), ('free', 1.5), ('fully', 1.5), ('gary', 1.5), ('gilsig', 1.5), ('goes', 1.5), ('gone', 1.5), ('grievous', 1.5), ('h20', 1.5), ('halloween', 1.5), ('hands', 1.5), ('happy', 1.5), ('headed', 1.5), ('help', 1.5), ('herc', 1.5), ('hercules', 1.5), ('hey', 1.5), ('high', 1.5), ('hit', 1.5), ('hunky', 1.5), ('hydra', 1.5), ('idle', 1.5), ('instantly', 1.5), ('integrated', 1.5), ('interesting', 1.5), ('itself', 1.5), ('jaleel', 1.5), ('jamie', 1.5), ('jane', 1.5), ('jessalyn', 1.5), ('keeping', 1.5), ('king', 1.5), ('kingdom', 1.5), ('knight', 1.5), ('lack', 1.5), ('last', 1.5), ('learn', 1.5), ('lee', 1.5), ('length', 1.5), ('let', 1.5), ('likes', 1.5), ('lively', 1.5), ('loses', 1.5), ('loss', 1.5), ('magic', 1.5), ('magical', 1.5), ('medieval', 1.5), ('mediocre', 1.5), ('middle', 1.5), ('mir', 1.5), ('moments', 1.5), ('morning', 1.5), ('mouse', 1.5), ('musical', 1.5), ('must', 1.5), ('nearly', 1.5), ('nicely', 1.5), ('none', 1.5), ('nowhere', 1.5), ('occasional', 1.5), ('ogre', 1.5), ('oldman', 1.5), ('origin', 1.5), ('otherwise', 1.5), ('paired', 1.5), ('palate', 1.5), ('parts', 1.5), ('picking', 1.5), ('piece', 1.5), ('pinchot', 1.5), ('pink', 1.5), ('pocahontas', 1.5), ('probably', 1.5), ('promising', 1.5), ('prove', 1.5), ('providing', 1.5), ('pulse', 1.5), ('pure', 1.5), ('race', 1.5), ('ranks', 1.5), ('real', 1.5), ('realized', 1.5), ('recall', 1.5), ('recent', 1.5), ('regarding', 1.5), ('remotely', 1.5), ('rest', 1.5), ('revolves', 1.5), ('rickles', 1.5), ('robot', 1.5), ('ruber', 1.5), ('run', 1.5), ('russian', 1.5), ('saturday', 1.5), ('schnazzy', 1.5), ('score', 1.5), ('sequences', 1.5), ('sexist', 1.5), ('seymour', 1.5), ('sharing', 1.5), ('shot', 1.5), ('showmanship', 1.5), ('shtick', 1.5), ('side', 1.5), ('signs', 1.5), ('singers', 1.5), ('songs', 1.5), ('sound', 1.5), ('specific', 1.5), ('spirited', 1.5), ('stan', 1.5), ('starring', 1.5), ('steal', 1.5), ('steals', 1.5), ('stink', 1.5), ('stumbling', 1.5), ('subpar', 1.5), ('substance', 1.5), ('sunken', 1.5), ('sword', 1.5), ('talent', 1.5), ('tech', 1.5), ('tgif', 1.5), ('those', 1.5), ('thrilled', 1.5), ('throne', 1.5), ('through', 1.5), ('tie', 1.5), ('timberland', 1.5), ('trapped', 1.5), ('tugboat', 1.5), ('turn', 1.5), ('urkel', 1.5), ('virus', 1.5), ('voice', 1.5), ('voiced', 1.5), ('warlord', 1.5), ('warner', 1.5), ('wasted', 1.5), ('white', 1.5), ('william', 1.5), ('win', 1.5), ('winston', 1.5), ('within', 1.5), ('work', 1.5), ('worried', 1.5), ('y2k', 1.5), ('year', 1.5), ('over', 1.3611111111111118), ('teen', 1.3611111111111118), ('television', 1.3611111111111118), ('these', 1.3611111111111118), ('1960', 1.3333333333333335), ('abo', 1.3333333333333335), ('accident', 1.3333333333333335), ('actor', 1.3333333333333335), ('adequate', 1.3333333333333335), ('again', 1.3333333333333335), ('also', 1.3333333333333335), ('american', 1.3333333333333335), ('apparently', 1.3333333333333335), ('appears', 1.3333333333333335), ('away', 1.3333333333333335), ('being', 1.3333333333333335), ('between', 1.3333333333333335), ('biggest', 1.3333333333333335), ('cable', 1.3333333333333335), ('car', 1.3333333333333335), ('claire', 1.3333333333333335), ('clear', 1.3333333333333335), ('coming', 1.3333333333333335), ('credits', 1.3333333333333335), ('crow', 1.3333333333333335), ('despite', 1.3333333333333335), ('did', 1.3333333333333335), ('didn', 1.3333333333333335), ('ditzy', 1.3333333333333335), ('either', 1.3333333333333335), ('entertaining', 1.3333333333333335), ('every', 1.3333333333333335), ('fed', 1.3333333333333335), ('flicks', 1.3333333333333335), ('found', 1.3333333333333335), ('front', 1.3333333333333335), ('fuck', 1.3333333333333335), ('half', 1.3333333333333335), ('hide', 1.3333333333333335), ('highway', 1.3333333333333335), ('hour', 1.3333333333333335), ('however', 1.3333333333333335), ('idea', 1.3333333333333335), ('jay', 1.3333333333333335), ('ll', 1.3333333333333335), ('look', 1.3333333333333335), ('lost', 1.3333333333333335), ('love', 1.3333333333333335), ('may', 1.3333333333333335), ('memento', 1.3333333333333335), ('mindset', 1.3333333333333335), ('mod', 1.3333333333333335), ('name', 1.3333333333333335), ('narrator', 1.3333333333333335), ('now', 1.3333333333333335), ('nudity', 1.3333333333333335), ('okay', 1.3333333333333335), ('opening', 1.3333333333333335), ('pet', 1.3333333333333335), ('pictures', 1.3333333333333335), ('plans', 1.3333333333333335), ('problem', 1.3333333333333335), ('quickly', 1.3333333333333335), ('redundant', 1.3333333333333335), ('rejected', 1.3333333333333335), ('restauranteur', 1.3333333333333335), ('sagemiller', 1.3333333333333335), ('screen', 1.3333333333333335), ('secret', 1.3333333333333335), ('seem', 1.3333333333333335), ('seems', 1.3333333333333335), ('sense', 1.3333333333333335), ('shelves', 1.3333333333333335), ('should', 1.3333333333333335), ('since', 1.3333333333333335), ('squad', 1.3333333333333335), ('stalkers', 1.3333333333333335), ('stars', 1.3333333333333335), ('starts', 1.3333333333333335), ('suspense', 1.3333333333333335), ('teenage', 1.3333333333333335), ('tells', 1.3333333333333335), ('than', 1.3333333333333335), ('times', 1.3333333333333335), ('toolbox', 1.3333333333333335), ('toward', 1.3333333333333335), ('tries', 1.3333333333333335), ('type', 1.3333333333333335), ('typically', 1.3333333333333335), ('ultimately', 1.3333333333333335), ('under', 1.3333333333333335), ('underwood', 1.3333333333333335), ('victim', 1.3333333333333335), ('where', 1.3333333333333335), ('while', 1.3333333333333335), ('won', 1.3333333333333335), ('world', 1.3333333333333335), ('would', 1.3333333333333335), ('write', 1.3333333333333335), ('so', 1.1851851851851858), ('as', 1.1428571428571432), ('they', 1.1250000000000009), ('her', 1.120370370370371), ('acting', 0.8888888888888884), ('find', 0.8888888888888884), ('some', 0.8888888888888884), ('thing', 0.8888888888888884), ('was', 0.8888888888888884), ('know', 0.857142857142857), ('around', 0.8333333333333333), ('bad', 0.8333333333333333), ('characters', 0.8333333333333333), ('do', 0.8333333333333333), ('she', 0.8333333333333333), ('too', 0.8333333333333333), ('two', 0.8333333333333333), ('really', 0.7500000000000002), ('1990s', 0.6666666666666667), ('20', 0.6666666666666667), ('ads', 0.6666666666666667), ('affair', 0.6666666666666667), ('ago', 0.6666666666666667), ('allowing', 0.6666666666666667), ('already', 0.6666666666666667), ('although', 0.6666666666666667), ('answers', 0.6666666666666667), ('anything', 0.6666666666666667), ('apart', 0.6666666666666667), ('apparent', 0.6666666666666667), ('apparitions', 0.6666666666666667), ('applaud', 0.6666666666666667), ('aren', 0.6666666666666667), ('arrow', 0.6666666666666667), ('assuming', 0.6666666666666667), ('attempting', 0.6666666666666667), ('avoid', 0.6666666666666667), ('awful', 0.6666666666666667), ('bar', 0.6666666666666667), ('basing', 0.6666666666666667), ('beauty', 0.6666666666666667), ('become', 0.6666666666666667), ('begins', 0.6666666666666667), ('bentley', 0.6666666666666667), ('blair', 0.6666666666666667), ('blowing', 0.6666666666666667), ('bond', 0.6666666666666667), ('bordering', 0.6666666666666667), ('boring', 0.6666666666666667), ('bottom', 0.6666666666666667), ('brief', 0.6666666666666667), ('brings', 0.6666666666666667), ('business', 0.6666666666666667), ('called', 0.6666666666666667), ('cannot', 0.6666666666666667), ('care', 0.6666666666666667), ('cash', 0.6666666666666667), ('cat', 0.6666666666666667), ('category', 0.6666666666666667), ('cause', 0.6666666666666667), ('certainly', 0.6666666666666667), ('chases', 0.6666666666666667), ('chasing', 0.6666666666666667), ('checked', 0.6666666666666667), ('chick', 0.6666666666666667), ('chopped', 0.6666666666666667), ('church', 0.6666666666666667), ('clich', 0.6666666666666667), ('cliche', 0.6666666666666667), ('close', 0.6666666666666667), ('clothes', 0.6666666666666667), ('clue', 0.6666666666666667), ('collect', 0.6666666666666667), ('comments', 0.6666666666666667), ('completely', 0.6666666666666667), ('concept', 0.6666666666666667), ('conclusion', 0.6666666666666667), ('confusing', 0.6666666666666667), ('considers', 0.6666666666666667), ('content', 0.6666666666666667), ('continues', 0.6666666666666667), ('contrary', 0.6666666666666667), ('contrived', 0.6666666666666667), ('convoluted', 0.6666666666666667), ('cop', 0.6666666666666667), ('correctly', 0.6666666666666667), ('costs', 0.6666666666666667), ('costumes', 0.6666666666666667), ('counted', 0.6666666666666667), ('couples', 0.6666666666666667), ('craziness', 0.6666666666666667), ('crazy', 0.6666666666666667), ('creepy', 0.6666666666666667), ('criminals', 0.6666666666666667), ('critique', 0.6666666666666667), ('cross', 0.6666666666666667), ('cute', 0.6666666666666667), ('cuts', 0.6666666666666667), ('dane', 0.6666666666666667), ('danes', 0.6666666666666667), ('danger', 0.6666666666666667), ('daniels', 0.6666666666666667), ('daylights', 0.6666666666666667), ('deal', 0.6666666666666667), ('decent', 0.6666666666666667), ('decided', 0.6666666666666667), ('decides', 0.6666666666666667), ('deliver', 0.6666666666666667), ('demands', 0.6666666666666667), ('derivative', 0.6666666666666667), ('described', 0.6666666666666667), ('desperate', 0.6666666666666667), ('dialogue', 0.6666666666666667), ('dies', 0.6666666666666667), ('different', 0.6666666666666667), ('dig', 0.6666666666666667), ('direct', 0.6666666666666667), ('director', 0.6666666666666667), ('disappearances', 0.6666666666666667), ('disbelief', 0.6666666666666667), ('dollar', 0.6666666666666667), ('doomed', 0.6666666666666667), ('downshifts', 0.6666666666666667), ('dreams', 0.6666666666666667), ('drink', 0.6666666666666667), ('drive', 0.6666666666666667), ('due', 0.6666666666666667), ('dust', 0.6666666666666667), ('echoes', 0.6666666666666667), ('edge', 0.6666666666666667), ('effects', 0.6666666666666667), ('elaborate', 0.6666666666666667), ('elements', 0.6666666666666667), ('elm', 0.6666666666666667), ('else', 0.6666666666666667), ('employ', 0.6666666666666667), ('ending', 0.6666666666666667), ('endless', 0.6666666666666667), ('engaging', 0.6666666666666667), ('ensure', 0.6666666666666667), ('enter', 0.6666666666666667), ('enters', 0.6666666666666667), ('entertain', 0.6666666666666667), ('entire', 0.6666666666666667), ('entry', 0.6666666666666667), ('episode', 0.6666666666666667), ('epps', 0.6666666666666667), ('equally', 0.6666666666666667), ('escape', 0.6666666666666667), ('especially', 0.6666666666666667), ('events', 0.6666666666666667), ('everything', 0.6666666666666667), ('evidence', 0.6666666666666667), ('exact', 0.6666666666666667), ('example', 0.6666666666666667), ('exception', 0.6666666666666667), ('excites', 0.6666666666666667), ('excuse', 0.6666666666666667), ('executed', 0.6666666666666667), ('explained', 0.6666666666666667), ('explanation', 0.6666666666666667), ('extremely', 0.6666666666666667), ('falls', 0.6666666666666667), ('fantasy', 0.6666666666666667), ('fatal', 0.6666666666666667), ('favor', 0.6666666666666667), ('feeling', 0.6666666666666667), ('fifteen', 0.6666666666666667), ('figured', 0.6666666666666667), ('final', 0.6666666666666667), ('finger', 0.6666666666666667), ('five', 0.6666666666666667), ('fledgling', 0.6666666666666667), ('flick', 0.6666666666666667), ('folks', 0.6666666666666667), ('follows', 0.6666666666666667), ('frequent', 0.6666666666666667), ('further', 0.6666666666666667), ('gain', 0.6666666666666667), ('geared', 0.6666666666666667), ('generally', 0.6666666666666667), ('generation', 0.6666666666666667), ('getting', 0.6666666666666667), ('giovanni', 0.6666666666666667), ('girlfriend', 0.6666666666666667), ('give', 0.6666666666666667), ('giving', 0.6666666666666667), ('gleason', 0.6666666666666667), ('guesswork', 0.6666666666666667), ('guys', 0.6666666666666667), ('hand', 0.6666666666666667), ('happen', 0.6666666666666667), ('hard', 0.6666666666666667), ('harder', 0.6666666666666667), ('heroes', 0.6666666666666667), ('heroine', 0.6666666666666667), ('highly', 0.6666666666666667), ('him', 0.6666666666666667), ('hip', 0.6666666666666667), ('holds', 0.6666666666666667), ('home', 0.6666666666666667), ('horror', 0.6666666666666667), ('hot', 0.6666666666666667), ('how', 0.6666666666666667), ('husband', 0.6666666666666667), ('immediately', 0.6666666666666667), ('implicitly', 0.6666666666666667), ('implied', 0.6666666666666667), ('include', 0.6666666666666667), ('incredible', 0.6666666666666667), ('independent', 0.6666666666666667), ('indication', 0.6666666666666667), ('indiglo', 0.6666666666666667), ('industry', 0.6666666666666667), ('inevitable', 0.6666666666666667), ('inexpensive', 0.6666666666666667), ('information', 0.6666666666666667), ('inside', 0.6666666666666667), ('insight', 0.6666666666666667), ('instance', 0.6666666666666667), ('instead', 0.6666666666666667), ('intelligence', 0.6666666666666667), ('interspersed', 0.6666666666666667), ('invariably', 0.6666666666666667), ('invention', 0.6666666666666667), ('jaded', 0.6666666666666667), ('jeopardy', 0.6666666666666667), ('joblo', 0.6666666666666667), ('judging', 0.6666666666666667), ('jumbled', 0.6666666666666667), ('justify', 0.6666666666666667), ('juvenile', 0.6666666666666667), ('kids', 0.6666666666666667), ('kills', 0.6666666666666667), ('kind', 0.6666666666666667), ('kudos', 0.6666666666666667), ('lazy', 0.6666666666666667), ('lead', 0.6666666666666667), ('leave', 0.6666666666666667), ('left', 0.6666666666666667), ('life', 0.6666666666666667), ('lines', 0.6666666666666667), ('literally', 0.6666666666666667), ('living', 0.6666666666666667), ('looking', 0.6666666666666667), ('looooot', 0.6666666666666667), ('lover', 0.6666666666666667), ('main', 0.6666666666666667), ('makes', 0.6666666666666667), ('making', 0.6666666666666667), ('manages', 0.6666666666666667), ('many', 0.6666666666666667), ('maryam', 0.6666666666666667), ('matter', 0.6666666666666667), ('me', 0.6666666666666667), ('mean', 0.6666666666666667), ('meant', 0.6666666666666667), ('meantime', 0.6666666666666667), ('melissa', 0.6666666666666667), ('melodrama', 0.6666666666666667), ('memorable', 0.6666666666666667), ('men', 0.6666666666666667), ('mentally', 0.6666666666666667), ('midnight', 0.6666666666666667), ('mood', 0.6666666666666667), ('mostly', 0.6666666666666667), ('mother', 0.6666666666666667), ('murder', 0.6666666666666667), ('murdered', 0.6666666666666667), ('neat', 0.6666666666666667), ('need', 0.6666666666666667), ('needs', 0.6666666666666667), ('neighborhood', 0.6666666666666667), ('never', 0.6666666666666667), ('new', 0.6666666666666667), ('night', 0.6666666666666667), ('nightmare', 0.6666666666666667), ('nightmares', 0.6666666666666667), ('nobody', 0.6666666666666667), ('norm', 0.6666666666666667), ('normal', 0.6666666666666667), ('oblivious', 0.6666666666666667), ('obsesses', 0.6666666666666667), ('obviously', 0.6666666666666667), ('occupying', 0.6666666666666667), ('off', 0.6666666666666667), ('offensive', 0.6666666666666667), ('offering', 0.6666666666666667), ('oh', 0.6666666666666667), ('older', 0.6666666666666667), ('omar', 0.6666666666666667), ('onto', 0.6666666666666667), ('opens', 0.6666666666666667), ('our', 0.6666666666666667), ('outfits', 0.6666666666666667), ('overall', 0.6666666666666667), ('overdoes', 0.6666666666666667), ('own', 0.6666666666666667), ('owner', 0.6666666666666667), ('package', 0.6666666666666667), ('packaged', 0.6666666666666667), ('parked', 0.6666666666666667), ('party', 0.6666666666666667), ('pass', 0.6666666666666667), ('password', 0.6666666666666667), ('personally', 0.6666666666666667), ('place', 0.6666666666666667), ('places', 0.6666666666666667), ('plain', 0.6666666666666667), ('played', 0.6666666666666667), ('playing', 0.6666666666666667), ('plays', 0.6666666666666667), ('point', 0.6666666666666667), ('police', 0.6666666666666667), ('ponders', 0.6666666666666667), ('potentially', 0.6666666666666667), ('predictable', 0.6666666666666667), ('presence', 0.6666666666666667), ('presents', 0.6666666666666667), ('problems', 0.6666666666666667), ('proceed', 0.6666666666666667), ('proceeds', 0.6666666666666667), ('produce', 0.6666666666666667), ('progresses', 0.6666666666666667), ('proliferation', 0.6666666666666667), ('provide', 0.6666666666666667), ('psychos', 0.6666666666666667), ('psychotherapy', 0.6666666666666667), ('questionable', 0.6666666666666667), ('questions', 0.6666666666666667), ('quite', 0.6666666666666667), ('rarely', 0.6666666666666667), ('rash', 0.6666666666666667), ('rated', 0.6666666666666667), ('rather', 0.6666666666666667), ('rating', 0.6666666666666667), ('receives', 0.6666666666666667), ('recycled', 0.6666666666666667), ('reformed', 0.6666666666666667), ('relatively', 0.6666666666666667), ('remembers', 0.6666666666666667), ('require', 0.6666666666666667), ('required', 0.6666666666666667), ('resident', 0.6666666666666667), ('respect', 0.6666666666666667), ('return', 0.6666666666666667), ('returns', 0.6666666666666667), ('revenge', 0.6666666666666667), ('ribisi', 0.6666666666666667), ('right', 0.6666666666666667), ('running', 0.6666666666666667), ('runtime', 0.6666666666666667), ('sad', 0.6666666666666667), ('salvation', 0.6666666666666667), ('save', 0.6666666666666667), ('saves', 0.6666666666666667), ('seeing', 0.6666666666666667), ('seemed', 0.6666666666666667), ('seemingly', 0.6666666666666667), ('seen', 0.6666666666666667), ('sequence', 0.6666666666666667), ('serious', 0.6666666666666667), ('serve', 0.6666666666666667), ('sets', 0.6666666666666667), ('several', 0.6666666666666667), ('showdown', 0.6666666666666667), ('shower', 0.6666666666666667), ('showing', 0.6666666666666667), ('shown', 0.6666666666666667), ('single', 0.6666666666666667), ('sitting', 0.6666666666666667), ('six', 0.6666666666666667), ('skip', 0.6666666666666667), ('slasher', 0.6666666666666667), ('slick', 0.6666666666666667), ('slightly', 0.6666666666666667), ('snag', 0.6666666666666667), ('snapshot', 0.6666666666666667), ('somehow', 0.6666666666666667), ('sometimes', 0.6666666666666667), ('somewhat', 0.6666666666666667), ('somewhere', 0.6666666666666667), ('sorta', 0.6666666666666667), ('sounding', 0.6666666666666667), ('sounds', 0.6666666666666667), ('soundtrack', 0.6666666666666667), ('span', 0.6666666666666667), ('special', 0.6666666666666667), ('spectacular', 0.6666666666666667), ('spending', 0.6666666666666667), ('spoon', 0.6666666666666667), ('spouts', 0.6666666666666667), ('spurned', 0.6666666666666667), ('stable', 0.6666666666666667), ('stake', 0.6666666666666667), ('stalk', 0.6666666666666667), ('states', 0.6666666666666667), ('statistics', 0.6666666666666667), ('stick', 0.6666666666666667), ('stir', 0.6666666666666667), ('stolen', 0.6666666666666667), ('strange', 0.6666666666666667), ('street', 0.6666666666666667), ('stretched', 0.6666666666666667), ('string', 0.6666666666666667), ('strip', 0.6666666666666667), ('strong', 0.6666666666666667), ('studio', 0.6666666666666667), ('stuff', 0.6666666666666667), ('such', 0.6666666666666667), ('suits', 0.6666666666666667), ('sure', 0.6666666666666667), ('survives', 0.6666666666666667), ('suspension', 0.6666666666666667), ('suspicion', 0.6666666666666667), ('suspicions', 0.6666666666666667), ('synopsis', 0.6666666666666667), ('taken', 0.6666666666666667), ('takes', 0.6666666666666667), ('tale', 0.6666666666666667), ('target', 0.6666666666666667), ('telling', 0.6666666666666667), ('terribly', 0.6666666666666667), ('thankful', 0.6666666666666667), ('theatrical', 0.6666666666666667), ('themselves', 0.6666666666666667), ('three', 0.6666666666666667), ('thrillers', 0.6666666666666667), ('thrilling', 0.6666666666666667), ('timex', 0.6666666666666667), ('title', 0.6666666666666667), ('together', 0.6666666666666667), ('tons', 0.6666666666666667), ('touches', 0.6666666666666667), ('towards', 0.6666666666666667), ('transfers', 0.6666666666666667), ('trying', 0.6666666666666667), ('turkey', 0.6666666666666667), ('turning', 0.6666666666666667), ('turns', 0.6666666666666667), ('types', 0.6666666666666667), ('undercover', 0.6666666666666667), ('undergoing', 0.6666666666666667), ('understanding', 0.6666666666666667), ('unfortunately', 0.6666666666666667), ('uniformly', 0.6666666666666667), ('unravel', 0.6666666666666667), ('unraveling', 0.6666666666666667), ('unscathed', 0.6666666666666667), ('unstable', 0.6666666666666667), ('unsuccessfully', 0.6666666666666667), ('until', 0.6666666666666667), ('use', 0.6666666666666667), ('validity', 0.6666666666666667), ('vehicles', 0.6666666666666667), ('viewed', 0.6666666666666667), ('viewer', 0.6666666666666667), ('visions', 0.6666666666666667), ('wanders', 0.6666666666666667), ('want', 0.6666666666666667), ('watched', 0.6666666666666667), ('wavers', 0.6666666666666667), ('ways', 0.6666666666666667), ('weird', 0.6666666666666667), ('wes', 0.6666666666666667), ('whatever', 0.6666666666666667), ('whole', 0.6666666666666667), ('wife', 0.6666666666666667), ('wisdom', 0.6666666666666667), ('witch', 0.6666666666666667), ('woman', 0.6666666666666667), ('woo', 0.6666666666666667), ('wooden', 0.6666666666666667), ('words', 0.6666666666666667), ('wrapped', 0.6666666666666667), ('written', 0.6666666666666667), ('wrong', 0.6666666666666667), ('years', 0.6666666666666667), ('yet', 0.6666666666666667), ('young', 0.6666666666666667), ('has', 0.38095238095238104), ('only', 0.38095238095238104), ('pretty', 0.38095238095238104), ('though', 0.38095238095238104), ('another', 0.3750000000000001), ('dead', 0.3750000000000001), ('enough', 0.3750000000000001), ('ex', 0.3750000000000001), ('get', 0.3750000000000001), ('other', 0.3750000000000001), ('same', 0.3750000000000001), ('scenes', 0.3750000000000001), ('still', 0.3750000000000001), ('throughout', 0.3750000000000001), ('much', 0.33333333333333315), ('movie', 0.2777777777777778), ('like', 0.2222222222222226), ('just', 0.1666666666666668), ('no', 0.1666666666666668), ('out', 0.1666666666666668), ('big', 0.16666666666666657), ('going', 0.16666666666666657), ('mess', 0.16666666666666657), ('them', 0.16666666666666657), ('very', 0.16666666666666657), ('course', 0.1111111111111113), ('with', 0.09374999999999989), ('actors', 0.08333333333333329), ('any', 0.08333333333333329), ('back', 0.08333333333333329), ('becomes', 0.08333333333333329), ('best', 0.08333333333333329), ('bored', 0.08333333333333329), ('break', 0.08333333333333329), ('came', 0.08333333333333329), ('can', 0.08333333333333329), ('chase', 0.08333333333333329), ('comes', 0.08333333333333329), ('complete', 0.08333333333333329), ('down', 0.08333333333333329), ('end', 0.08333333333333329), ('ever', 0.08333333333333329), ('feels', 0.08333333333333329), ('first', 0.08333333333333329), ('flash', 0.08333333333333329), ('gets', 0.08333333333333329), ('given', 0.08333333333333329), ('got', 0.08333333333333329), ('had', 0.08333333333333329), ('head', 0.08333333333333329), ('isn', 0.08333333333333329), ('likely', 0.08333333333333329), ('line', 0.08333333333333329), ('long', 0.08333333333333329), ('member', 0.08333333333333329), ('might', 0.08333333333333329), ('missing', 0.08333333333333329), ('mold', 0.08333333333333329), ('poorly', 0.08333333333333329), ('quick', 0.08333333333333329), ('reason', 0.08333333333333329), ('review', 0.08333333333333329), ('someone', 0.08333333333333329), ('something', 0.08333333333333329), ('star', 0.08333333333333329), ('start', 0.08333333333333329), ('strain', 0.08333333333333329), ('took', 0.08333333333333329), ('watching', 0.08333333333333329), ('well', 0.08333333333333329), ('worth', 0.08333333333333329), ('at', 0.07407407407407397), ('we', 0.06060606060606071), ('you', 0.06060606060606071), ('always', 0.05555555555555565), ('attempt', 0.05555555555555565), ('cast', 0.05555555555555565), ('fact', 0.05555555555555565), ('little', 0.05555555555555565), ('my', 0.05555555555555565), ('nothing', 0.05555555555555565), ('others', 0.05555555555555565), ('people', 0.05555555555555565), ('production', 0.05555555555555565), ('re', 0.05555555555555565), ('shows', 0.05555555555555565), ('strangeness', 0.05555555555555565), ('your', 0.05555555555555565), ('be', 0.04166666666666674), ('if', 0.023809523809523787), ('its', 0.023809523809523787), ('when', 0.023809523809523787), ('most', 0.02083333333333337), ('for', 0.0), ('from', 0.0), ('good', 0.0), ('see', 0.0), ('story', 0.0), ('their', 0.0), ('time', 0.0), ('up', 0.0)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
        "\n",
        "nltk.download('movie_reviews')\n",
        "txt = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()[:5]]\n",
        "vectorizer = CountVectorizer()\n",
        "features = vectorizer.fit_transform(txt).toarray()\n",
        "labels = [1, 0, 1, 0, 1]\n",
        "mi = SelectKBest(mutual_info_classif, k=5)\n",
        "mi.fit(features, labels)\n",
        "scores = mi.scores_\n",
        "ranks = sorted(zip(vectorizer.get_feature_names_out(), scores), key=lambda x: x[1], reverse=True)\n",
        "print(\"\\nTop features ranked by importance (Mutual Information):\\n\", ranks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774214a6-81e8-4cf9-bda7-53da862cb651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ranked movie reviews based on similarity to query:\n",
            "Rank 1: Review: it is movies like these that make a jaded movie viewer thankful for the invention of the timex indig..., Similarity: 0.33462586998939514\n",
            "Rank 2: Review:  \" quest for camelot \" is warner bros . ' first feature-length , fully-animated attempt to steal clo..., Similarity: 0.280952513217926\n",
            "Rank 3: Review: synopsis : a mentally unstable man undergoing psychotherapy saves a boy from a potentially fatal acc..., Similarity: 0.21732941269874573\n",
            "Rank 4: Review: plot : two teen couples go to a church party , drink and then drive . \n",
            "they get into an accident . \n",
            "..., Similarity: 0.18735744059085846\n",
            "Rank 5: Review: the happy bastard's quick movie review \n",
            "damn that y2k bug . \n",
            "it's got a head start in this movie sta..., Similarity: 0.1448916494846344\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install sentence-transformers\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "query = \"This movie was fantastic!\"\n",
        "txt_emb = model.encode(txt)\n",
        "qry_emb = model.encode([query])\n",
        "cos_sim = cosine_similarity(qry_emb, txt_emb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on extracting features from text data. What were the key concepts or techniques you found most beneficial in understanding the process?\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The NLTK movie_reviews dataset became a very important introduction into feature extraction, selection, and ranking of similarity. Standard feature extraction techniques-BoW, TF-IDF, POS tagging-were joined with advanced models such as BERT and helped me to have a better understanding of text representation. I had some problems trying to settle on a feature selection technique. This is because there are so many ways of reducing the text data into the appropriate dimensions. Also, the extensive text from movie reviews in BERT was challenging, but breaking them into embeddings helped. This exercise is directly related to the fields of NLP and text mining. Mastery of the techniques in this course will, therefore, enhance my capability to handle text data in a much neater and organized way, hence enabling the extraction of knowledge necessary to develop highly accurate models required in tasks such as Sentiment Analysis and Document Ranking."
      ],
      "metadata": {
        "id": "39hFHeD2TkiV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HNJSG7C6Tsi5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}