{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DymRJbxDBCnf"
   },
   "source": [
    "# **INFO5731 In-class Exercise 2**\n",
    "\n",
    "The purpose of this exercise is to understand users' information needs, and then collect data from different sources for analysis by implementing web scraping using Python.\n",
    "\n",
    "**Expectations**:\n",
    "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
    "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
    "*   Write complete answers and run all the cells before submission.\n",
    "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
    "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
    "\n",
    "**Total points**: 40\n",
    "\n",
    "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
    "\n",
    "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBKvD6O_TY6e"
   },
   "source": [
    "## Question 1 (10 Points)\n",
    "Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? Specify the amount of data needed for analysis. Provide detailed steps for collecting and saving the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Research Question: How has the discussion of electric vehicles evolved on Reddit over the past few years?\n",
    "Data Collection: We will scrape Reddit for posts mentioning \"electric vehicles\" across multiple subreddits. In this case, features to be extracted for the posts are title, author, date created, and score. This will give an idea of how often discussions occur, by what user engagement and sentiment trend EVs take on Reddit.\n",
    "\n",
    "Number of Instances: At least 1000 Reddit posts mentioning \"electric vehicles.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9RqrlwdTfvl"
   },
   "source": [
    "## Question 2 (10 Points)\n",
    "Write Python code to collect a dataset of 1000 samples related to the question discussed in Question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4XvRknixTh1g",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import praw\n",
    "red = praw.Reddit(client_id='iG7q_9MkzmXJuubBGygfgg', \n",
    "                     client_secret='h3vs37btLN69CYdodfEItroAZaiMlw', \n",
    "                     user_agent='my_app/0.1 by VenuV')\n",
    "data = []\n",
    "for submission in red.subreddit(\"all\").search(\"electric vehicles\", limit=1000):\n",
    "    data.append({\n",
    "        \"title\": submission.title,\n",
    "        \"author\": submission.author.name,\n",
    "        \"created\": submission.created_utc,\n",
    "        \"score\": submission.score,\n",
    "        \"url\": submission.url,\n",
    "    })\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('redditEVdata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03jb4GZsBkBS"
   },
   "source": [
    "## Question 3 (10 Points)\n",
    "Write Python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"XYZ\". The articles should be published in the last 10 years (2014-2024).\n",
    "\n",
    "The following information from the article needs to be collected:\n",
    "\n",
    "(1) Title of the article\n",
    "\n",
    "(2) Venue/journal/conference being published\n",
    "\n",
    "(3) Year\n",
    "\n",
    "(4) Authors\n",
    "\n",
    "(5) Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cikVKDXdTbzE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write your answer here\n",
    "from scholarly import scholarly\n",
    "key='electric vehicles'\n",
    "qry = scholarly.search_pubs(key)\n",
    "lst1=[]\n",
    "\n",
    "for i in range(100):\n",
    "    try:      \n",
    "        article=next(qry)\n",
    "        yr=int(article['bib']['pub_year'])\n",
    "        if 2014 <= yr <= 2024:\n",
    "            lst1.append({'title' : article['bib']['title'], 'venue' : article['bib']['title'], 'year' : yr, 'authors' : ', '.join(article['bib']['author']),\n",
    "                         'abstract' : article.get('bib', {}).get('abstract', 'N/a')})\n",
    "        time.sleep(2)\n",
    "    except StopIteration:\n",
    "        print(\"No more articles to fetch.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching article {i}: {e}\")\n",
    "        break\n",
    "df=pd.DataFrame(lst1)\n",
    "df.to_csv('articles.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJDe71iLB616"
   },
   "source": [
    "## Question 4A (10 Points)\n",
    "Develop Python code to collect data from social media platforms like Reddit, Instagram, Twitter (formerly known as X), Facebook, or any other. Use hashtags, keywords, usernames, or user IDs to gather the data.\n",
    "\n",
    "\n",
    "\n",
    "Ensure that the collected data has more than four columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MtKskTzbCLaU",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title       author  \\\n",
      "0    Biden urged to ban China-made electric vehicles       tommos   \n",
      "1  Biden Calls Chinese Electric Vehicles a Securi...      newzee1   \n",
      "2  1.8 Million Barrels of Oil a Day Avoided from ...     Wagamaga   \n",
      "3  Honda says making cheap electric vehicles is t...   marketrent   \n",
      "4  US suggests possibility of penalties if produc...  Lemonn_time   \n",
      "\n",
      "          created_utc  score  comments  \\\n",
      "0 2024-04-13 00:15:30   7606      1789   \n",
      "1 2024-02-29 13:14:34   8602      2498   \n",
      "2 2023-12-10 17:47:37   7345      1385   \n",
      "3 2023-10-26 00:08:18   9434      1460   \n",
      "4 2024-05-15 18:11:57   3127       782   \n",
      "\n",
      "                                                 url  \n",
      "0     https://www.bbc.com/news/articles/cyerg64dn97o  \n",
      "1  https://www.nytimes.com/2024/02/29/us/politics...  \n",
      "2  https://cleantechnica.com/2023/12/09/1-8-milli...  \n",
      "3  https://arstechnica.com/cars/2023/10/honda-can...  \n",
      "4  https://www.yahoo.com/finance/news/us-suggests...  \n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "red = praw.Reddit(client_id='iG7q_9MkzmXJuubBGygfgg', \n",
    "                     client_secret='h3vs37btLN69CYdodfEItroAZaiMlw', \n",
    "                     user_agent='my_app/0.1 by VenuV')\n",
    "subred = red.subreddit(\"technology\")\n",
    "red_data = []\n",
    "for res in subred.search(\"electric vehicles\", limit=1000):\n",
    "    red_data.append({\n",
    "        \"title\": res.title,\n",
    "        \"author\": res.author.name if res.author else \"N/A\",\n",
    "        \"created_utc\": res.created_utc,\n",
    "        \"score\": res.score,\n",
    "        \"comments\": res.num_comments, \n",
    "        \"url\": res.url,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(red_data)\n",
    "df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "\n",
    "df.to_csv('reddit_technology_ev_posts.csv', index=False)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55W9AMdXCSpV"
   },
   "source": [
    "## Question 4B (10 Points)\n",
    "If you encounter challenges with Question-4 web scraping using Python, employ any online tools such as ParseHub or Octoparse for data extraction. Introduce the selected tool, outline the steps for web scraping, and showcase the final output in formats like CSV or Excel.\n",
    "\n",
    "\n",
    "\n",
    "Upload a document (Word or PDF File) in any shared storage (preferably UNT OneDrive) and add the publicly accessible link in the below code cell.\n",
    "\n",
    "Please only choose one option for question 4. If you do both options, we will grade only the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "I57NXsauCec2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public link to the extracted data: https://myunt-my.sharepoint.com/:x:/r/personal/venugopalreddyvennapusa_my_unt_edu/Documents/INFO5737/run_results.csv?d=w42d25c4ef6a24e7bad2afcb4421babc2&csf=1&web=1&e=WKAV4L\n"
     ]
    }
   ],
   "source": [
    "public_link = 'https://myunt-my.sharepoint.com/:x:/r/personal/venugopalreddyvennapusa_my_unt_edu/Documents/INFO5737/run_results.csv?d=w42d25c4ef6a24e7bad2afcb4421babc2&csf=1&web=1&e=WKAV4L'\n",
    "print(\"Public link to the extracted data:\", public_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZOhks1dXWEe"
   },
   "source": [
    "# Mandatory Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqmHVEwaWhbV"
   },
   "source": [
    "**Important: Reflective Feedback on Web Scraping and Data Collection**\n",
    "\n",
    "\n",
    "\n",
    "Please share your thoughts and feedback on the web scraping and data collection exercises you have completed in this assignment. Consider the following points in your response:\n",
    "\n",
    "\n",
    "\n",
    "Learning Experience: Describe your overall learning experience in working on web scraping tasks. What were the key concepts or techniques you found most beneficial in understanding the process of extracting data from various online sources?\n",
    "\n",
    "\n",
    "\n",
    "Challenges Encountered: Were there specific difficulties in collecting data from certain websites, and how did you overcome them? If you opted for the non-coding option, share your experience with the chosen tool.\n",
    "\n",
    "\n",
    "\n",
    "Relevance to Your Field of Study: How might the ability to gather and analyze data from online sources enhance your work or research?\n",
    "\n",
    "**(no grading of your submission if this question is left unanswered)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akAVJn9YBTQT"
   },
   "source": [
    "Learning Experience:\n",
    "Web scraping tasks were useful in extracting data from online sources. The learning of APIs, including such libraries as praw for Reddit and BeautifulSoup for HTML parsing, was done. But the most valuable thing was to understand how to structure the request and programmatically handle the data extracted. \n",
    "\n",
    "Challenges Encountered:\n",
    "I had problems when fetching API credentials, especially for social media sites such as Twitter and Reddit. That is very time-consuming, having to find one's way in the maze of API documentation and getting through lots of authentication complications. Working my way around it, I looked for non-programming tools like ParseHub that offered another approach toward data extraction without having to gain API access directly.\n",
    "\n",
    "Relevance to Your Field of Study:\n",
    "Among the main skills in my field are web scraping and data collection, which help me in collecting and analyzing real-world data. These techniques will be useful for performing sentiment analyses, detecting trends, and other data-driven analyses that can inform decision-making and research related to business analytics and information systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "FBKvD6O_TY6e",
    "E9RqrlwdTfvl",
    "03jb4GZsBkBS",
    "jJDe71iLB616",
    "55W9AMdXCSpV",
    "4ulBZ6yhCi9F",
    "6SmvS7nSfbj8",
    "sZOhks1dXWEe"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
